{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "age_gender_emotion_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMVWmc9XexmPu/pLtFofvmM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gohjx8808/age-gender-emotion-prediction/blob/main/age_gender_emotion_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGzW22aP0atD",
        "outputId": "f53e3ae8-037c-47fe-84bc-916f6b81f6d3"
      },
      "source": [
        "!pip3 install mtcnn matplotlib opencv-python Pillow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.5.2)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40JTTSFD04xe"
      },
      "source": [
        "# **Code starts here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw5g09VhN-hE"
      },
      "source": [
        "## **Image Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUy5ky6k5ofC"
      },
      "source": [
        "### **Extract faces out of source image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyd9Rbe65_3M"
      },
      "source": [
        "Face extraction is done by part due to large amount of data and time constraint in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ciw0DJLhNVqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf66969b-1114-4b15-a358-78866bb07d5f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nD8MeWGNh9x"
      },
      "source": [
        "import mtcnn\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFRYgbTS6LWU"
      },
      "source": [
        "Draw boundary boxes of extracted faces and store extracted faces into Google Drive\n",
        "\n",
        "\n",
        "To make extracted image square:\n",
        "*   the center point of the extracted image is calculated\n",
        "*   the maximum between width and height is calculated\n",
        "*   new boundary boxes are drawn with the max value\n",
        "\n",
        "*** Only faces with confidence level > 0.99 is extracted and saved\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb9rcMPB57xi"
      },
      "source": [
        "def draw_facebox(filePath,result_list):\n",
        "  # load the image\n",
        "  imageData = cv2.cvtColor(cv2.imread(filePath), cv2.COLOR_BGR2RGB)\n",
        "  # plot the image\n",
        "  # plt.imshow(imageData)\n",
        "  # get the context for drawing boxes\n",
        "  # ax = plt.gca()\n",
        "  # plot each box\n",
        "  fileName=os.path.basename(filePath)\n",
        "  counter=1\n",
        "  for result in result_list:\n",
        "    # get coordinates\n",
        "    x, y, width, height = result['box']\n",
        "\n",
        "    x1 = max(0,x)\n",
        "    x2 = x+width\n",
        "    y1 = max(0,y)\n",
        "    y2 = y+height\n",
        "\n",
        "    xCenter = int((x1 + x2) / 2)\n",
        "    yCenter = int((y1 + y2) / 2)\n",
        "\n",
        "    calculatedWidth=xCenter - x1\n",
        "    calculatedHeight=yCenter - y1\n",
        "    maxWidthHeight=int(max(calculatedWidth,calculatedHeight))\n",
        "\n",
        "    if yCenter-maxWidthHeight<0 or yCenter+maxWidthHeight>imageData.shape[0] or xCenter-maxWidthHeight<0 or xCenter+maxWidthHeight>imageData.shape[1]:\n",
        "      maxWidthHeight=int(min(calculatedWidth,calculatedHeight))\n",
        "    \n",
        "    if result['confidence']>0.99:\n",
        "      croppedFace=imageData[yCenter-maxWidthHeight:yCenter+maxWidthHeight,xCenter-maxWidthHeight:xCenter+maxWidthHeight]\n",
        "      resizedImage=cv2.resize(croppedFace,(224,224))\n",
        "      splittedNameExtension=fileName.split('.')\n",
        "      cv2.imwrite('gdrive/My Drive/age-gender-emotion-prediction/UTKface_inthewild/cropped_faces/'+splittedNameExtension[0]+'_'+str(counter)+'.'+splittedNameExtension[1], cv2.cvtColor(resizedImage,cv2.COLOR_BGR2RGB))\n",
        "    # create the shape\n",
        "    # rect = plt.Rectangle((xCenter-maxWidthHeight, yCenter-maxWidthHeight), maxWidthHeight*2,maxWidthHeight*2, fill=False, color='red')\n",
        "    # draw the box\n",
        "    # ax.add_patch(rect)\n",
        "    counter+=1\n",
        "  # show the plot\n",
        "  # plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3P2e4_j7Iv4"
      },
      "source": [
        "Part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqK0nQ0k1ht7"
      },
      "source": [
        "targetFacesPath1='gdrive/My Drive/age-gender-emotion-prediction/UTKface_inthewild/part1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwgKpy8a0Y5D"
      },
      "source": [
        "for filename in os.listdir(targetFacesPath1):\n",
        "  filePath=os.path.join(targetFacesPath1,filename)\n",
        "  image = cv2.cvtColor(cv2.imread(filePath), cv2.COLOR_BGR2RGB)\n",
        "  detector = mtcnn.MTCNN()\n",
        "  faces = detector.detect_faces(image)\n",
        "  draw_facebox(filePath,faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLoPDPY0OFLz",
        "outputId": "139de26b-b76f-484c-ec3e-c72864a84ccb"
      },
      "source": [
        "print (len([filename for filename in os.listdir('gdrive/My Drive/age-gender-emotion-prediction/UTKface_inthewild/cropped_faces')]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEBo4ZPy7MXH"
      },
      "source": [
        "Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v1JPgyYVsjm"
      },
      "source": [
        "targetFacesPath2='gdrive/My Drive/age-gender-emotion-prediction/UTKface_inthewild/part2'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR_n5hNG3S-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59096288-ddd0-40b4-c2dc-0574e7c65fd0"
      },
      "source": [
        "for filename in os.listdir(targetFacesPath2):\n",
        "  filePath=os.path.join(targetFacesPath2,filename)\n",
        "  image = cv2.cvtColor(cv2.imread(filePath), cv2.COLOR_BGR2RGB)\n",
        "  detector = mtcnn.MTCNN()\n",
        "  faces = detector.detect_faces(image)\n",
        "  draw_facebox(filePath,faces)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f300ae65ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f300ae65ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogJrxCuQN35y",
        "outputId": "cb72b108-6c80-47b1-aaa3-df7c55ee1fe7"
      },
      "source": [
        "print (len([filename for filename in os.listdir('gdrive/My Drive/age-gender-emotion-prediction/UTKface_inthewild/cropped_faces')]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzitcX157NjB"
      },
      "source": [
        "Part 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBaTmqjDVuYr"
      },
      "source": [
        "targetFacesPath3='gdrive/My Drive/age-gender-emotion-prediction/UTKface_inthewild/part3'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqcuSsHBVnRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57bdd2f-033f-4bfe-bf79-f94c018c9571"
      },
      "source": [
        "for filename in os.listdir(targetFacesPath3):\n",
        "  filePath=os.path.join(targetFacesPath3,filename)\n",
        "  image = cv2.cvtColor(cv2.imread(filePath), cv2.COLOR_BGR2RGB)\n",
        "  detector = mtcnn.MTCNN()\n",
        "  faces = detector.detect_faces(image)\n",
        "  draw_facebox(filePath,faces)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f54e9edd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f54bf3320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTRBBJDZOqU1"
      },
      "source": [
        "print (len([filename for filename in os.listdir('gdrive/My Drive/age-gender-emotion-prediction/UTKface_inthewild/cropped_faces')]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xez95aM-ZIVB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}